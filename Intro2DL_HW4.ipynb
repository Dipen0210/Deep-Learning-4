{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Of_VLtyDMPjk",
        "outputId": "083dab6b-038d-402a-e758-ae5dc41d8d09"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Define the target function as the sum of 3 sinusoids\n",
        "def target_function(x):\n",
        "    return np.sin(2 * np.pi * 1.0 * x) + 0.5 * np.sin(2 * np.pi * 3.0 * x) + 0.25 * np.sin(2 * np.pi * 5.0 * x)\n",
        "\n",
        "# Generate dataset with 4000 points\n",
        "x = np.linspace(0, 1, 4000)  # 4000 points between 0 and 1\n",
        "y = target_function(x)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "x_train = torch.tensor(x, dtype=torch.float32).view(-1, 1)\n",
        "y_train = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Define the original 3-layer MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 1)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Define the LFF (Learnable Fourier Feature) layer\n",
        "class LFF(nn.Module):\n",
        "    def __init__(self, in_features, out_features, scale=1.0, init=\"iso\", sincos=False):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.sincos = sincos\n",
        "        self.out_features = out_features\n",
        "        self.scale = scale\n",
        "        if self.sincos:\n",
        "            self.linear = nn.Linear(in_features, out_features // 2)\n",
        "        else:\n",
        "            self.linear = nn.Linear(in_features, out_features)\n",
        "        if init == \"iso\":\n",
        "            nn.init.normal_(self.linear.weight, 0, scale / in_features)\n",
        "            nn.init.normal_(self.linear.bias, 0, 1)\n",
        "        else:\n",
        "            nn.init.uniform_(self.linear.weight, -scale / in_features, scale / in_features)\n",
        "            nn.init.uniform_(self.linear.bias, -1, 1)\n",
        "        if self.sincos:\n",
        "            nn.init.zeros_(self.linear.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = np.pi * self.linear(x)\n",
        "        if self.sincos:\n",
        "            return torch.cat([torch.sin(x), torch.cos(x)], dim=-1)\n",
        "        else:\n",
        "            return torch.sin(x)\n",
        "\n",
        "# Define the FourierModel with the LFF layer\n",
        "class FourierModel(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim):\n",
        "        super(FourierModel, self).__init__()\n",
        "        self.input_layer = LFF(state_dim, hidden_dim, scale=0.1, init=\"iso\", sincos=False)\n",
        "        self.mid_layer = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.output = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.mid_layer(x)\n",
        "        x = self.relu2(x)\n",
        "        return self.output(x)\n",
        "\n",
        "# Initialize models, loss function, and optimizers\n",
        "mlp_model = MLP()\n",
        "fourier_model = FourierModel(state_dim=1, action_dim=1, hidden_dim=100)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "mlp_optimizer = optim.Adam(mlp_model.parameters(), lr=0.002)\n",
        "fourier_optimizer = optim.Adam(fourier_model.parameters(), lr=0.002)\n",
        "\n",
        "# Training loop for both models\n",
        "num_epochs = 4000\n",
        "mlp_losses = []\n",
        "fourier_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train MLP model\n",
        "    mlp_model.train()\n",
        "    mlp_optimizer.zero_grad()\n",
        "    mlp_y_pred = mlp_model(x_train)\n",
        "    mlp_loss = criterion(mlp_y_pred, y_train)\n",
        "    mlp_loss.backward()\n",
        "    mlp_optimizer.step()\n",
        "    mlp_losses.append(mlp_loss.item())\n",
        "\n",
        "    # Train Fourier model\n",
        "    fourier_model.train()\n",
        "    fourier_optimizer.zero_grad()\n",
        "    fourier_y_pred = fourier_model(x_train)\n",
        "    fourier_loss = criterion(fourier_y_pred, y_train)\n",
        "    fourier_loss.backward()\n",
        "    fourier_optimizer.step()\n",
        "    fourier_losses.append(fourier_loss.item())\n",
        "\n",
        "    # Print loss every 100 epochs\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], MLP Loss: {mlp_loss.item():.4f}, Fourier Loss: {fourier_loss.item():.4f}\")\n",
        "\n",
        "# Plot the training loss for both models\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(mlp_losses, label=\"MLP Loss\")\n",
        "plt.plot(fourier_losses, label=\"Fourier Model Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the target function vs. the learned functions\n",
        "with torch.no_grad():\n",
        "    mlp_y_learned = mlp_model(x_train).numpy()\n",
        "    fourier_y_learned = fourier_model(x_train).numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x, y, label=\"Target Function\", color='blue')\n",
        "plt.plot(x, mlp_y_learned, label=\"MLP Learned Function\", color='red', linestyle='--')\n",
        "plt.plot(x, fourier_y_learned, label=\"Fourier Model Learned Function\", color='green', linestyle='--')\n",
        "plt.title(\"Target Function vs MLP and Fourier Model Learned Functions\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenvGenAI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
